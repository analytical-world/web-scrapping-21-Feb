{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e78ce099-e6f5-4999-abfe-b44e97534e9b",
   "metadata": {},
   "source": [
    "Q1. What is Web Scraping? Why is it Used? Give three areas where Web Scraping is used to get data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1eedbf6-5c9a-4ef8-ba1c-dcbe296310ae",
   "metadata": {},
   "source": [
    "Sol 1: Web scraping is the process of collecting structured web data in an automated manner. Itâ€™s also widely known as web data extraction or web data scraping.\n",
    "\n",
    "It is used to extract publicly available data in an automotive way.\n",
    "\n",
    "Some of the main use cases of web scraping include price monitoring, price intelligence, news monitoring, lead generation, and market research among many others."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdb032d3-7b67-4c24-a529-e7a4cc109327",
   "metadata": {},
   "source": [
    "Q2. What are the different methods used for Web Scraping?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7efae37-0277-41d5-8bc0-68bfbebf3b89",
   "metadata": {},
   "source": [
    "Sol 2: 1). Web Scraping Libraries:\n",
    "These are pre built function and tools for scraping web data. These libraries simplifies the process of scraping the data in html webpages (eg. beautiful soup, scrapy,selenium, etc.)\n",
    "\n",
    "2).  Web Scraping APIs:\n",
    "Web scraping APIs enable developers to access and extract relevant data from websites.Websites can provide web scraping APIs, such as Twitter API, Amazon API, and Facebook API."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "679e1edb-0caf-408e-8910-1f2abd4c7ac8",
   "metadata": {},
   "source": [
    "Q3. Q3. What is Beautiful Soup? Why is it used?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54d00567-8357-4d60-b1e0-34e4c5350380",
   "metadata": {},
   "source": [
    "Beautiful Soup is a Python library that makes it easy to scrape information from web pages.\n",
    "It pulls out data from html and xml files."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11ef4ca9-ff15-4a5d-a4c2-401bfc7c6c32",
   "metadata": {},
   "source": [
    "Q4. Why is flask used in this Web Scraping project?"
   ]
  },
  {
   "cell_type": "raw",
   "id": "63b8d0d4-173c-48bd-a39a-dd95a39e8be9",
   "metadata": {},
   "source": [
    "Sol: Flask is a micro web python framework that is commonly used for building web application including web scraping application. \n",
    "Flask can be used to create a web application that can scrape data from websites, process the data, and display it to user. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5429545b-9a21-4cfe-b954-91a8b9095938",
   "metadata": {},
   "source": [
    "Q5. Write the names of AWS services used in this project. Also, explain the use of each service."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50701808-f937-43e8-9a46-e360c316bf02",
   "metadata": {},
   "source": [
    "Sol: 1. Beanstalk: AWS Elastic Beanstalk is a fully managed service that makes it easy to deploy and scale web application. It provides environment for hosting our web applications that automatically handles deployment. \n",
    "\n",
    "2.Codepipeline: AWS codepipeline is a continuous integration and continuous delivery (CI/CD) service used to build, test and deploy code. Codepipeline integrates with other AWS services like Elastic Beanstalk, Codecommit, Codebuild, CodeDeploy allowig user to build a complete CI/CD pipeline."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
